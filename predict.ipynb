{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms.v2 import TrivialAugmentWide, ToImage\n",
    "\n",
    "from nn_training import train_and_eval, select_device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1633466478.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 55\u001b[1;36m\u001b[0m\n\u001b[1;33m    tensor_imgs_test = aggregate_images(pd.read_csv(self.img_catalog_file_paths[]), test_img_dir_path)\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def split_train_val(df_img_catalog, val_proportion:float):\n",
    "    rng = np.random.default_rng()\n",
    "    val_indices = rng.choice(len(df_img_catalog), size=int(len(df_img_catalog)*val_proportion), replace=False)\n",
    "    df_val = df_img_catalog.iloc[np.isin(df_img_catalog.index, val_indices)]\n",
    "    df_train = df_img_catalog.iloc[np.isin(df_img_catalog.index, val_indices, invert=True)]\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def aggregate_images(df_img_catalog, img_dir_path):\n",
    "    img_dir_path = Path(img_dir_path)\n",
    "    img_paths = [img_dir_path.joinpath(i) for i in df_img_catalog[\"filename\"]]\n",
    "    pil_imgs = [Image.open(i) for i in img_paths]\n",
    "    to_torch_img = ToImage()\n",
    "    tensor_imgs = [to_torch_img(i) for i in pil_imgs]\n",
    "    expanded_tensor_imgs = [torch.unsqueeze(i, dim=0) for i in tensor_imgs]\n",
    "    aggregated_imgs = torch.cat(expanded_tensor_imgs)\n",
    "    return aggregated_imgs\n",
    "\n",
    "\n",
    "class Image_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.img_catalog_file_paths = {\n",
    "            \"original_train\": Path(\"train_catalog.csv\"),\n",
    "            \"train\": Path(\"train_catalog_train.csv\"),\n",
    "            \"val\": Path(\"train_catalog_val.csv\"),\n",
    "            \"test\": Path(\"test_catalog.csv\"),\n",
    "        }\n",
    "\n",
    "        self.img_dir_paths = {\n",
    "            \"train\":Path(\"train/train\"),\n",
    "            \"test\":Path(\"test/test\"),\n",
    "        }\n",
    "\n",
    "        self.tensor_imgs_file_paths = {\n",
    "            \"train\": Path(\"train_imgs_train.pt\"),\n",
    "            \"val\": Path(\"train_imgs_val.pt\"),\n",
    "            \"test\": Path(\"test_imgs.pt\"),\n",
    "        }\n",
    "\n",
    "        self.set_transform(None)\n",
    "\n",
    "    def generate(self, validation_split_proportion,):\n",
    "        df_img_catalog_original_train = pd.read_csv(self.img_catalog_file_paths[\"original_train\"]).drop(columns=\"id\")\n",
    "        df_img_catalog_train, df_img_catalog_val = split_train_val(df_img_catalog_original_train, validation_split_proportion)\n",
    "        df_img_catalog_train.to_csv(self.img_catalog_file_paths[\"train\"], index=False)\n",
    "        df_img_catalog_val.to_csv(self.img_catalog_file_paths[\"val\"], index=False)\n",
    "\n",
    "        tensor_imgs_train = aggregate_images(df_img_catalog_train, self.img_dir_paths[\"train\"])\n",
    "        torch.save(tensor_imgs_train, self.tensor_imgs_file_paths[\"train\"])\n",
    "        tensor_imgs_val = aggregate_images(df_img_catalog_val, self.img_dir_paths[\"train\"])\n",
    "        torch.save(tensor_imgs_val, self.tensor_imgs_file_paths[\"val\"])\n",
    "        tensor_imgs_test = aggregate_images(pd.read_csv(self.img_catalog_file_paths[\"test\"]), self.img_dir_paths[\"test\"])\n",
    "        torch.save(tensor_imgs_test, self.tensor_imgs_file_paths[\"test\"])\n",
    "\n",
    "    def load(self, split, device):\n",
    "        self.split = split\n",
    "\n",
    "        if split == \"test\":\n",
    "            self.tensor_imgs = torch.load(self.tensor_imgs_file_paths[\"test\"]).to(device)\n",
    "        elif split in {\"train\", \"val\"}:\n",
    "            self.tensor_imgs = torch.load(self.tensor_imgs_file_paths[split]).to(device)\n",
    "            self.tensor_img_labels = torch.from_numpy(pd.read_csv(self.img_catalog_file_paths[split])[\"label\"].to_numpy()).to(device)\n",
    "            assert len(self.tensor_imgs) == len(self.tensor_img_labels)\n",
    "        else: raise ValueError\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.split == \"test\":\n",
    "            x = self.tensor_imgs[index]\n",
    "            return x\n",
    "        elif self.split in {\"train\", \"val\"}:\n",
    "            x = self.tensor_imgs[index]\n",
    "            y = self.tensor_img_labels[index]\n",
    "            return x, y \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_catalog_original_train = pd.read_csv(\"train.csv\").drop(columns=\"id\")\n",
    "\n",
    "df_img_catalog_train, df_img_catalog_val = split_train_val(df_img_catalog_original_train, val_proportion=0.25)\n",
    "\n",
    "df_img_catalog_train.to_csv(\"train_split_catalog_train.csv\", index=False)\n",
    "df_img_catalog_val.to_csv(\"train_split_catalog_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MV1012-BC-12_obj00001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MV1012-BC-12_obj00003.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV1012-BC-12_obj00004.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MV1012-BC-12_obj00005.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MV1012-BC-12_obj00008.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>MV1012-BC-8_obj01909.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>MV1012-BC-8_obj01910.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>MV1012-BC-8_obj01911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>MV1012-BC-8_obj01913.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>MV1012-BC-8_obj01914.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6490 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  label\n",
       "0     MV1012-BC-12_obj00001.jpg      0\n",
       "1     MV1012-BC-12_obj00003.jpg      2\n",
       "2     MV1012-BC-12_obj00004.jpg      3\n",
       "3     MV1012-BC-12_obj00005.jpg      0\n",
       "4     MV1012-BC-12_obj00008.jpg      4\n",
       "...                         ...    ...\n",
       "6485   MV1012-BC-8_obj01909.jpg      0\n",
       "6486   MV1012-BC-8_obj01910.jpg      3\n",
       "6487   MV1012-BC-8_obj01911.jpg      3\n",
       "6488   MV1012-BC-8_obj01913.jpg      9\n",
       "6489   MV1012-BC-8_obj01914.jpg      0\n",
       "\n",
       "[6490 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img_catalog_train = pd.read_csv(\"train_split_catalog_train.csv\")\n",
    "df_img_catalog_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MV1012-BC-12_obj00002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MV1012-BC-12_obj00006.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV1012-BC-12_obj00015.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MV1012-BC-12_obj00023.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MV1012-BC-12_obj00024.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>MV1012-BC-8_obj01890.jpg</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>MV1012-BC-8_obj01891.jpg</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>MV1012-BC-8_obj01897.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>MV1012-BC-8_obj01904.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>MV1012-BC-8_obj01912.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  label\n",
       "0     MV1012-BC-12_obj00002.jpg      1\n",
       "1     MV1012-BC-12_obj00006.jpg      1\n",
       "2     MV1012-BC-12_obj00015.jpg      1\n",
       "3     MV1012-BC-12_obj00023.jpg      5\n",
       "4     MV1012-BC-12_obj00024.jpg      3\n",
       "...                         ...    ...\n",
       "2158   MV1012-BC-8_obj01890.jpg     16\n",
       "2159   MV1012-BC-8_obj01891.jpg     19\n",
       "2160   MV1012-BC-8_obj01897.jpg     21\n",
       "2161   MV1012-BC-8_obj01904.jpg      1\n",
       "2162   MV1012-BC-8_obj01912.jpg      1\n",
       "\n",
       "[2163 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img_catalog_val = pd.read_csv(\"train_split_catalog_val.csv\")\n",
    "df_img_catalog_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate images for easy loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maybe_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
